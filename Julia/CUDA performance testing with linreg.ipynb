{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CuArray{Int64,1}:\n",
       "  5\n",
       " 10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = CuArray([5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "abstract type LinearModel end\n",
    "mutable struct LinearRegression{P} <: LinearModel\n",
    "    A::Float64\n",
    "    B::Float64\n",
    "    predict::P\n",
    "    regressors::Array{LinearModel}\n",
    "    function LinearRegression(x::Array,y::Array; cuda = false)\n",
    "        # a = ((∑y)(∑x^2)-(∑x)(∑xy)) / (n(∑x^2) - (∑x)^2)\n",
    "        # b = (x(∑xy) - (∑x)(∑y)) / n(∑x^2) - (∑x)^2\n",
    "        regressors = []\n",
    "        if cuda == true\n",
    "            x = CuArray(x)\n",
    "            y = CuArray(y)\n",
    "        end\n",
    "        if length(x) != length(y)\n",
    "            throw(ArgumentError(\"The array shape does not match!\"))\n",
    "        end\n",
    "        # Get our Summations:\n",
    "        Σx = sum(x)\n",
    "        Σy = sum(y)\n",
    "        # dot x and y\n",
    "        xy = x .* y\n",
    "        # ∑dot x and y\n",
    "        Σxy = sum(xy)\n",
    "        # dotsquare x\n",
    "        x2 = x .^ 2\n",
    "        # ∑ dotsquare x\n",
    "        Σx2 = sum(x2)\n",
    "        # n = sample size\n",
    "        n = length(x)\n",
    "        # Calculate a\n",
    "        a = (((Σy) * (Σx2)) - ((Σx * (Σxy)))) / ((n * (Σx2))-(Σx^2))\n",
    "        # Calculate b\n",
    "        b = ((n*(Σxy)) - (Σx * Σy)) / ((n * (Σx2)) - (Σx ^ 2))\n",
    "        predict(xt::Array) = (xt = [i = a + (b * i) for i in xt])\n",
    "        P = typeof(predict)\n",
    "        return new{P}(a, b, predict, [])\n",
    "    end\n",
    "        function LinearRegression(x::DataFrame,y::Array)\n",
    "            # a = ((∑y)(∑x^2)-(∑x)(∑xy)) / (n(∑x^2) - (∑x)^2)\n",
    "            # b = (x(∑xy) - (∑x)(∑y)) / n(∑x^2) - (∑x)^2\n",
    "            regressors = []\n",
    "            count = 1\n",
    "            [push!(regressors, LinearRegression(feature, y) for feature in x)]\n",
    "            a = nothing\n",
    "            b = nothing\n",
    "            for m in regressors\n",
    "                if a != nothing\n",
    "                    a = mean(a, m.a)\n",
    "                    b = mean(b, m.b)\n",
    "                else\n",
    "                    a = m.a\n",
    "                    b = m.b\n",
    "                end\n",
    "            end\n",
    "            predict(xt::DataFrame) = _compare_predCon(models, xt)\n",
    "            P = typeof(predict)\n",
    "            return new{P}(a, b, predict, regressors)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lathe.preprocess: TrainTestSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th></tr><tr><th></th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5,000,000 rows × 2 columns</p><tr><th>1</th><td>0.577005</td><td>-0.971065</td></tr><tr><th>2</th><td>-1.12369</td><td>-0.646088</td></tr><tr><th>3</th><td>1.45753</td><td>-1.08604</td></tr><tr><th>4</th><td>0.239653</td><td>1.09619</td></tr><tr><th>5</th><td>-0.692247</td><td>-0.282517</td></tr><tr><th>6</th><td>-0.702029</td><td>1.48493</td></tr><tr><th>7</th><td>-0.023858</td><td>0.701455</td></tr><tr><th>8</th><td>1.10218</td><td>-1.17157</td></tr><tr><th>9</th><td>0.567547</td><td>0.134177</td></tr><tr><th>10</th><td>-0.154495</td><td>-0.614274</td></tr><tr><th>11</th><td>-0.0206048</td><td>-1.47767</td></tr><tr><th>12</th><td>0.984598</td><td>-1.39026</td></tr><tr><th>13</th><td>0.280465</td><td>1.80941</td></tr><tr><th>14</th><td>0.317778</td><td>-0.458131</td></tr><tr><th>15</th><td>0.223292</td><td>-0.804576</td></tr><tr><th>16</th><td>0.00230328</td><td>-1.12961</td></tr><tr><th>17</th><td>-1.3122</td><td>0.696079</td></tr><tr><th>18</th><td>-0.496621</td><td>1.47771</td></tr><tr><th>19</th><td>-1.86086</td><td>0.431618</td></tr><tr><th>20</th><td>-0.37195</td><td>-0.842543</td></tr><tr><th>21</th><td>0.358322</td><td>1.52302</td></tr><tr><th>22</th><td>-0.422654</td><td>1.85635</td></tr><tr><th>23</th><td>-1.47808</td><td>0.780614</td></tr><tr><th>24</th><td>-1.29756</td><td>1.96902</td></tr><tr><th>25</th><td>-1.319</td><td>0.691083</td></tr><tr><th>26</th><td>-0.0196345</td><td>0.00899154</td></tr><tr><th>27</th><td>1.85271</td><td>0.0873672</td></tr><tr><th>28</th><td>-0.989435</td><td>0.846209</td></tr><tr><th>29</th><td>1.22851</td><td>-1.62522</td></tr><tr><th>30</th><td>0.307118</td><td>0.778689</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& A & B\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.577005 & -0.971065 \\\\\n",
       "\t2 & -1.12369 & -0.646088 \\\\\n",
       "\t3 & 1.45753 & -1.08604 \\\\\n",
       "\t4 & 0.239653 & 1.09619 \\\\\n",
       "\t5 & -0.692247 & -0.282517 \\\\\n",
       "\t6 & -0.702029 & 1.48493 \\\\\n",
       "\t7 & -0.023858 & 0.701455 \\\\\n",
       "\t8 & 1.10218 & -1.17157 \\\\\n",
       "\t9 & 0.567547 & 0.134177 \\\\\n",
       "\t10 & -0.154495 & -0.614274 \\\\\n",
       "\t11 & -0.0206048 & -1.47767 \\\\\n",
       "\t12 & 0.984598 & -1.39026 \\\\\n",
       "\t13 & 0.280465 & 1.80941 \\\\\n",
       "\t14 & 0.317778 & -0.458131 \\\\\n",
       "\t15 & 0.223292 & -0.804576 \\\\\n",
       "\t16 & 0.00230328 & -1.12961 \\\\\n",
       "\t17 & -1.3122 & 0.696079 \\\\\n",
       "\t18 & -0.496621 & 1.47771 \\\\\n",
       "\t19 & -1.86086 & 0.431618 \\\\\n",
       "\t20 & -0.37195 & -0.842543 \\\\\n",
       "\t21 & 0.358322 & 1.52302 \\\\\n",
       "\t22 & -0.422654 & 1.85635 \\\\\n",
       "\t23 & -1.47808 & 0.780614 \\\\\n",
       "\t24 & -1.29756 & 1.96902 \\\\\n",
       "\t25 & -1.319 & 0.691083 \\\\\n",
       "\t26 & -0.0196345 & 0.00899154 \\\\\n",
       "\t27 & 1.85271 & 0.0873672 \\\\\n",
       "\t28 & -0.989435 & 0.846209 \\\\\n",
       "\t29 & 1.22851 & -1.62522 \\\\\n",
       "\t30 & 0.307118 & 0.778689 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5000000×2 DataFrame\u001b[0m\n",
       "\u001b[1m     Row \u001b[0m│\u001b[1m A          \u001b[0m\u001b[1m B          \u001b[0m\n",
       "\u001b[1m         \u001b[0m│\u001b[90m Float64    \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────────┼────────────────────────\n",
       "       1 │  0.577005   -0.971065\n",
       "       2 │ -1.12369    -0.646088\n",
       "       3 │  1.45753    -1.08604\n",
       "       4 │  0.239653    1.09619\n",
       "       5 │ -0.692247   -0.282517\n",
       "       6 │ -0.702029    1.48493\n",
       "       7 │ -0.023858    0.701455\n",
       "       8 │  1.10218    -1.17157\n",
       "       9 │  0.567547    0.134177\n",
       "      10 │ -0.154495   -0.614274\n",
       "      11 │ -0.0206048  -1.47767\n",
       "    ⋮    │     ⋮           ⋮\n",
       " 4999991 │  1.29261    -1.77421\n",
       " 4999992 │ -1.0067     -0.509862\n",
       " 4999993 │ -1.14882    -0.419361\n",
       " 4999994 │  2.11255    -0.997588\n",
       " 4999995 │  1.63904     0.663972\n",
       " 4999996 │  0.0634828  -0.49296\n",
       " 4999997 │  1.67508    -2.06518\n",
       " 4999998 │ -0.107832    0.267083\n",
       " 4999999 │ -1.66285     0.0482086\n",
       " 5000000 │  0.659585    0.158184\n",
       "\u001b[36m              4999979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(:A => randn(5000000), :B => randn(5000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\u001b[1m3747974×2 DataFrame\u001b[0m\n",
       "\u001b[1m     Row \u001b[0m│\u001b[1m A           \u001b[0m\u001b[1m B         \u001b[0m\n",
       "\u001b[1m         \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────────┼────────────────────────\n",
       "       1 │  0.577005    -0.971065\n",
       "       2 │ -1.12369     -0.646088\n",
       "       3 │  1.45753     -1.08604\n",
       "       4 │  0.239653     1.09619\n",
       "       5 │ -0.692247    -0.282517\n",
       "       6 │ -0.702029     1.48493\n",
       "       7 │ -0.023858     0.701455\n",
       "       8 │  0.567547     0.134177\n",
       "       9 │ -0.0206048   -1.47767\n",
       "      10 │  0.280465     1.80941\n",
       "      11 │  0.317778    -0.458131\n",
       "    ⋮    │      ⋮           ⋮\n",
       " 3747965 │  0.919352    -0.999579\n",
       " 3747966 │ -0.438849    -0.791899\n",
       " 3747967 │ -0.655646     1.32953\n",
       " 3747968 │  1.57285     -0.182869\n",
       " 3747969 │ -0.499785     0.483187\n",
       " 3747970 │  0.110402     0.376069\n",
       " 3747971 │  1.29261     -1.77421\n",
       " 3747972 │ -1.14882     -0.419361\n",
       " 3747973 │  2.11255     -0.997588\n",
       " 3747974 │  0.659585     0.158184\n",
       "\u001b[36m              3747953 rows omitted\u001b[0m, \u001b[1m1252026×2 DataFrame\u001b[0m\n",
       "\u001b[1m     Row \u001b[0m│\u001b[1m A          \u001b[0m\u001b[1m B          \u001b[0m\n",
       "\u001b[1m         \u001b[0m│\u001b[90m Float64    \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────────┼────────────────────────\n",
       "       1 │  1.10218    -1.17157\n",
       "       2 │ -0.154495   -0.614274\n",
       "       3 │  0.984598   -1.39026\n",
       "       4 │  0.223292   -0.804576\n",
       "       5 │ -0.37195    -0.842543\n",
       "       6 │ -0.422654    1.85635\n",
       "       7 │ -0.543937    0.0529983\n",
       "       8 │  1.51111    -1.027\n",
       "       9 │ -0.0902189  -1.17756\n",
       "      10 │  1.00588    -1.44981\n",
       "      11 │ -0.137596    1.10294\n",
       "    ⋮    │     ⋮           ⋮\n",
       " 1252017 │ -1.16558    -0.597107\n",
       " 1252018 │ -0.516582   -1.43453\n",
       " 1252019 │ -0.942669    0.413806\n",
       " 1252020 │ -0.187885   -0.676059\n",
       " 1252021 │ -1.0067     -0.509862\n",
       " 1252022 │  1.63904     0.663972\n",
       " 1252023 │  0.0634828  -0.49296\n",
       " 1252024 │  1.67508    -2.06518\n",
       " 1252025 │ -0.107832    0.267083\n",
       " 1252026 │ -1.66285     0.0482086\n",
       "\u001b[36m              1252005 rows omitted\u001b[0m)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = TrainTestSplit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.799333 seconds (20.39 M allocations: 1.069 GiB, 4.14% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1252026-element Array{Float64,1}:\n",
       " 0.0007593812368251255\n",
       " 0.0006031036239309942\n",
       " 0.0007447593375925508\n",
       " 0.000650084630560349\n",
       " 0.0005760612869706101\n",
       " 0.0005697558771464991\n",
       " 0.000554673367806285\n",
       " 0.0008102356529406358\n",
       " 0.0006110969318424915\n",
       " 0.0007474061098006959\n",
       " 0.0006052051410636166\n",
       " 0.0007227634485248923\n",
       " 0.00047798855040247766\n",
       " ⋮\n",
       " 0.0006798954610642182\n",
       " 0.000297086561590541\n",
       " 0.0004773663033831785\n",
       " 0.0005580751920272239\n",
       " 0.0005050876651470564\n",
       " 0.0005989512879201476\n",
       " 0.0004971244974083756\n",
       " 0.0008261441700263702\n",
       " 0.000630211015944771\n",
       " 0.0008306262880419847\n",
       " 0.0006089065807559879\n",
       " 0.00041552772483634547"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time LinearRegression(train[!, :A], train[!, :B]).predict(test[!, :A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.127757 seconds (13.78 M CPU allocations: 714.041 MiB, 1.30% gc time) (12 GPU allocations: 114.379 MiB, 2.06% gc time of which 0.65% spent allocating)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1252026-element Array{Float64,1}:\n",
       " 0.0007593812368251252\n",
       " 0.0006031036239309938\n",
       " 0.0007447593375925504\n",
       " 0.0006500846305603486\n",
       " 0.0005760612869706097\n",
       " 0.0005697558771464987\n",
       " 0.0005546733678062846\n",
       " 0.0008102356529406353\n",
       " 0.0006110969318424911\n",
       " 0.0007474061098006955\n",
       " 0.0006052051410636161\n",
       " 0.0007227634485248919\n",
       " 0.0004779885504024772\n",
       " ⋮\n",
       " 0.0006798954610642178\n",
       " 0.0002970865615905405\n",
       " 0.000477366303383178\n",
       " 0.0005580751920272234\n",
       " 0.000505087665147056\n",
       " 0.0005989512879201472\n",
       " 0.0004971244974083752\n",
       " 0.0008261441700263697\n",
       " 0.0006302110159447706\n",
       " 0.0008306262880419844\n",
       " 0.0006089065807559874\n",
       " 0.000415527724836345"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.@time LinearRegression(train[!, :A], train[!, :B], cuda = true).predict(test[!, :A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\u001b[1m3748152×2 DataFrame\u001b[0m\n",
       "\u001b[1m     Row \u001b[0m│\u001b[1m A          \u001b[0m\u001b[1m B          \u001b[0m\n",
       "\u001b[1m         \u001b[0m│\u001b[90m Float64    \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────────┼────────────────────────\n",
       "       1 │  0.607555   -1.67637\n",
       "       2 │  0.169965   -0.677239\n",
       "       3 │  1.68827    -0.0997401\n",
       "       4 │ -0.110792    0.392875\n",
       "       5 │  0.952066    0.140255\n",
       "       6 │  0.809013    0.350373\n",
       "       7 │  0.725505    0.582751\n",
       "       8 │  0.702776    0.898695\n",
       "       9 │ -1.15123     2.15362\n",
       "      10 │  0.402691   -0.0669361\n",
       "      11 │  0.357018    1.39073\n",
       "    ⋮    │     ⋮           ⋮\n",
       " 3748143 │  0.593798    0.393911\n",
       " 3748144 │ -0.45311     0.667211\n",
       " 3748145 │ -0.764961    0.411348\n",
       " 3748146 │  0.0594568  -0.407051\n",
       " 3748147 │  0.111333    0.818817\n",
       " 3748148 │ -1.65268    -0.120496\n",
       " 3748149 │ -1.15869     0.335531\n",
       " 3748150 │ -2.16815     1.77178\n",
       " 3748151 │  0.72471     0.425346\n",
       " 3748152 │ -0.469236   -0.59999\n",
       "\u001b[36m              3748131 rows omitted\u001b[0m, \u001b[1m1251848×2 DataFrame\u001b[0m\n",
       "\u001b[1m     Row \u001b[0m│\u001b[1m A         \u001b[0m\u001b[1m B          \u001b[0m\n",
       "\u001b[1m         \u001b[0m│\u001b[90m Float64   \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────────┼───────────────────────\n",
       "       1 │ -1.54024    0.66129\n",
       "       2 │  0.155527  -1.60692\n",
       "       3 │  1.135     -1.57298\n",
       "       4 │  0.540986  -0.511578\n",
       "       5 │ -1.18137    0.526994\n",
       "       6 │  1.0566    -1.23039\n",
       "       7 │ -0.166647   2.15469\n",
       "       8 │ -0.23232   -0.266512\n",
       "       9 │  1.18115    0.385873\n",
       "      10 │ -0.364181  -1.65275\n",
       "      11 │ -2.20213    2.19904\n",
       "    ⋮    │     ⋮          ⋮\n",
       " 1251839 │  0.291408   0.973608\n",
       " 1251840 │  1.50486   -1.24374\n",
       " 1251841 │  0.207348  -1.72541\n",
       " 1251842 │ -0.432353   0.38723\n",
       " 1251843 │ -1.49266    0.941283\n",
       " 1251844 │ -1.14999   -1.2456\n",
       " 1251845 │ -1.38628    0.179998\n",
       " 1251846 │ -0.406798  -0.990291\n",
       " 1251847 │  0.591301   0.424404\n",
       " 1251848 │  1.28425   -1.42248\n",
       "\u001b[36m             1251827 rows omitted\u001b[0m)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(:A => randn(5000000), :B => randn(5000000))\n",
    "train, test = TrainTestSplit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
